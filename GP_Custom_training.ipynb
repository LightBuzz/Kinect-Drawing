{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GP_Custom_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYAy8/eNIg6bK49qd38D+s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khaledAIVR/Kinect-Drawing/blob/master/GP_Custom_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa5c6b4wmM17"
      },
      "source": [
        "import shutil\n",
        "shutil.rmtree(\"/content/sample_data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJUsANxh1qA1"
      },
      "source": [
        "\n",
        "# -------------------------------------------------------\n",
        "# Obtain coords\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image, ImageDraw\n",
        "import sys\n",
        "from skimage.feature import hog\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "import pickle\n",
        "import sys\n",
        "import os\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnFmNfU83u0e"
      },
      "source": [
        "def data_augmentation(final_img_path):\n",
        "    \"\"\"\n",
        "    input: Original img path\n",
        "    Output: returns a list of numpy images\n",
        "    \"\"\"\n",
        "    img_data_list = []\n",
        "    img = Image.open(final_img_path)\n",
        "    for i in range(1, 8):\n",
        "        aug_img = img.rotate(45 * i)\n",
        "        aug_img.save(\"/content/aug_imgs/aug_img_\" + str(i) +  \".png\")\n",
        "        img_data_list.append(asarray(aug_img))\n",
        "\n",
        "    return img_data_list\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvNyLVdh2EdI"
      },
      "source": [
        "def do_it_all(data_path):\n",
        "    #print(\"111\")\n",
        "    #Preprocessing and obtain the data coord from the txt file\n",
        "    f = open(data_path, \"r\")\n",
        "    _ = f.readline()\n",
        "\n",
        "    data = f.readline()\n",
        "\n",
        "    f.close()\n",
        "\n",
        "    data_list = data.split(\" \")\n",
        "    data_list_coordinates = []\n",
        "    for item in data_list:\n",
        "        (x, y) = item.split(\",\")\n",
        "        (x, y) = math.ceil(float(x)), math.ceil(float(y))\n",
        "        data_list_coordinates.append((x, y))\n",
        "    # -------------------------------------------------------\n",
        "    #print(\"222\")\n",
        "    # Construct binary image using coords\n",
        "    my_screen_width = 1920\n",
        "    my_screen_height = 1080\n",
        "    # let's create a 6 x 6 matrix with all pixels in black color\n",
        "    img = np.zeros((my_screen_width, my_screen_height), np.uint8)\n",
        "\n",
        "    for data in data_list_coordinates:\n",
        "        img[data[0], data[1]] = 255\n",
        "\n",
        "    cv2.imwrite(\"t1.png\", img)\n",
        "    # -------------------------------------------------------\n",
        "    #print(\"333\")\n",
        "    # Mirroring\n",
        "    # load the image, create the mirrored image, and the result placeholder\n",
        "    img = Image.open(\"t1.png\")\n",
        "    mirror = img.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.ROTATE_90)\n",
        "    mirror.save(\"t1.png\")\n",
        "    # -------------------------------------------------------\n",
        "    #print(\"444\")\n",
        "    # Connect points using a thick line\n",
        "    # from google.colab.patches import cv2_imshow\n",
        "    img = cv2.imread(\"t1.png\")\n",
        "    (pre_x, pre_y) = data_list_coordinates[0]\n",
        "    for (x, y) in data_list_coordinates[1:]:\n",
        "        img = cv2.line(img, (pre_x, pre_y), (x, y), (255, 255, 255), 40)\n",
        "        (pre_x, pre_y) = (x, y)\n",
        "\n",
        "    # save our image as a \"png\" image\n",
        "    # cv2_imshow(img)\n",
        "    cv2.imwrite(\"t2.png\", img)\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    #print(\"555\")\n",
        "    # Cropping\n",
        "    img_orig = cv2.imread('t2.png', 0)\n",
        "\n",
        "    mask = np.zeros(img_orig.shape, np.uint8)  # mask image the final image without small pieces\n",
        "\n",
        "    # using findContours func to find the none-zero pieces\n",
        "    contours, hierarchy = cv2.findContours(img_orig, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # draw the white paper and eliminate the small pieces (less than 1000000 px). This px count is the same as the QR code dectection\n",
        "    index = 0\n",
        "    for cnt in contours:\n",
        "        if cv2.contourArea(cnt) > 100:\n",
        "            cv2.drawContours(mask, [cnt], 0, 255,\n",
        "                             -1)  # the [] around cnt and 3rd argument 0 mean only the particular contour is drawn\n",
        "\n",
        "            # Build a ROI to crop the QR\n",
        "            x, y, w, h = cv2.boundingRect(cnt)\n",
        "            roi = mask[y:y + h, x:x + w]\n",
        "            # crop the original QR based on the ROI\n",
        "            img_crop = img_orig[y:y + h, x:x + w]\n",
        "            # use cropped mask image (roi) to get rid of all small pieces\n",
        "            img_final = img_crop * (roi / 255)\n",
        "\n",
        "    cv2.imwrite('t2_cropped.png', img_final)\n",
        "    # -------------------------------------------------------\n",
        "    #print(\"666\")\n",
        "    # Padding\n",
        "\n",
        "    # read image\n",
        "    img = cv2.imread('t2_cropped.png')\n",
        "    ht, wd, cc = img.shape\n",
        "    ww = hh = (math.ceil(max(wd, ht) / 28) + 1) * 28\n",
        "\n",
        "    # create new image of desired size and color (blue) for padding\n",
        "    color = (0, 0, 0)\n",
        "    result = np.full((hh, ww, cc), color, dtype=np.uint8)\n",
        "\n",
        "    # compute center offset\n",
        "    xx = (ww - wd) // 2\n",
        "    yy = (hh - ht) // 2\n",
        "\n",
        "    # copy img image into center of result image\n",
        "    result[yy:yy + ht, xx:xx + wd] = img\n",
        "\n",
        "    # view result\n",
        "    # cv2_imshow(result)\n",
        "    # save result\n",
        "    cv2.imwrite(\"padded_cropped_img.png\", result)\n",
        "    # -------------------------------------------------------\n",
        "    #print(\"777\")\n",
        "    # resizing PIL   ->perfect\n",
        "    image = Image.open('padded_cropped_img.png')\n",
        "    new_image = image.resize((28, 28))\n",
        "    new_image.save('padded_cropped_shrinked_img.png')\n",
        "    final_img_path = 'padded_cropped_shrinked_img.png'\n",
        "    # -------------------------------------------------------\n",
        "    # load the image\n",
        "    image = Image.open(final_img_path)\n",
        "    # convert image to numpy array\n",
        "    original_img_data = asarray(image)\n",
        "    # -------------------------------------------------------\n",
        "    #Data Augmentation\n",
        "    img_and_augmented_data_list = []\n",
        "    img_and_augmented_data_list.append(original_img_data)\n",
        "    img_and_augmented_data_list = img_and_augmented_data_list + data_augmentation(final_img_path)\n",
        "\n",
        "    #print(len(img_and_augmented_data_list))\n",
        "\n",
        "    return img_and_augmented_data_list"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKzquGC52HTO"
      },
      "source": [
        "\n",
        "\n",
        "def hog_alorithm(training_data):\n",
        "    print(len(training_data))\n",
        "    training_data_resized = []\n",
        "    for img in training_data:\n",
        "        training_data_resized.append(cv2.resize(img, (80, 80)))\n",
        "\n",
        "    ppc = 16\n",
        "    hog_images = []\n",
        "    hog_features = []\n",
        "    for image in training_data_resized:\n",
        "        fd,hog_image = hog(image, orientations=8, pixels_per_cell=(ppc,ppc),cells_per_block=(4, 4),block_norm= 'L2',visualize=True)\n",
        "        hog_images.append(hog_image)\n",
        "        hog_features.append(fd)\n",
        "\n",
        "    print(len(hog_features))\n",
        "    hog_features = np.array(hog_features)\n",
        "    return hog_features\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6eUqx0w4Q7e"
      },
      "source": [
        "#Unzipping 7z:\n",
        "!pip install py7zr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8IUG9SM4cQO"
      },
      "source": [
        "!py7zr x /content/DataSet_v_3.7z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yt9ULZz2a_s"
      },
      "source": [
        "\n",
        "training_data = []\n",
        "classes_sizes = []\n",
        "labels = []\n",
        "data_path = \"/content/DataSet v_3\"\n",
        "\n",
        "for class_path in os.listdir(data_path):\n",
        "\n",
        "    class_path = os.path.join(data_path, class_path)\n",
        "\n",
        "\n",
        "    for shape_path in os.listdir(class_path):\n",
        "        print(shape_path)\n",
        "        shape_path = os.path.join(class_path, shape_path)\n",
        "\n",
        "        if os.stat(shape_path).st_size == 0:\n",
        "            os.remove(shape_path)\n",
        "            continue\n",
        "\n",
        "        training_data = training_data + do_it_all(shape_path)\n",
        "\n",
        "    class_len = len(os.listdir(class_path))\n",
        "    classes_sizes.append(class_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7jbZemN_0dg"
      },
      "source": [
        "len(training_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM3yF9mJ4nD_"
      },
      "source": [
        "classes_sizes_copy = classes_sizes.copy()\n",
        "for i in range(len(classes_sizes_copy)):\n",
        "    classes_sizes_copy[i] = classes_sizes_copy[i] * 8\n",
        "classes_sizes_copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7x8tHQE6EQ3"
      },
      "source": [
        "classes_sizes = classes_sizes_copy.copy()"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3dMXXVZ7gJ3"
      },
      "source": [
        "classes_sizes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdkXchyR2SD1"
      },
      "source": [
        "\n",
        "hog_features = hog_alorithm(training_data)\n",
        "\n",
        "\n",
        "labels = np.zeros((classes_sizes[0], 1), dtype=\"int8\")\n",
        "for i in range(1, len(classes_sizes)):\n",
        "    label_i = np.zeros((classes_sizes[i], 1), dtype=\"int8\") + i\n",
        "    labels = np.concatenate((labels, label_i))\n",
        "\n",
        "clf = svm.SVC(probability=True)\n",
        "data_frame = np.hstack((hog_features, labels))\n",
        "np.random.shuffle(data_frame)\n",
        "\n",
        "percentage = 80\n",
        "partition = int(len(hog_features)*percentage/100)\n",
        "\n",
        "x_train, x_test = data_frame[:partition,:-1],  data_frame[partition:,:-1]\n",
        "y_train, y_test = data_frame[:partition,-1:].ravel() , data_frame[partition:,-1:].ravel()\n",
        "\n",
        "clf.fit(x_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48jfh8E8-4G3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107d6436-6ea0-4f86-be8d-e8d36a7f4452"
      },
      "source": [
        "hog_features.shape"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3216, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6OOm49C-LQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f789153-31e8-4003-be23-ed1ab2e0da5c"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3216, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KngA6VeD2Uil"
      },
      "source": [
        "\n",
        "import pickle\n",
        "# save the model to disk\n",
        "filename = 'finalized_model_v4.pkl'\n",
        "pickle.dump(clf, open(filename, 'wb'))"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3Du7loiFjlI",
        "outputId": "b8b7254c-3efd-45fa-c1fa-1942c5d30e23"
      },
      "source": [
        "classes_sizes"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[272, 696, 888, 680, 680]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVlI7cSY764o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}